import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import shap
import matplotlib.pyplot as plt

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
# ==========================================
st.set_page_config(
    page_title="Ù†Ø¸Ø§Ù… ØªÙˆÙ‚Ø¹ Ø§Ù„Ø®Ø±ÙˆØ¬ Ø§Ù„Ø°ÙƒÙŠ (Live)",
    page_icon="ğŸ¥",
    layout="wide"
)

st.markdown("""
<style>
    .big-font { font-size:24px !important; font-weight: bold; }
    .metric-card { background-color: #f0f2f6; padding: 20px; border-radius: 10px; margin-bottom: 10px; }
    div[data-testid="stMetricValue"] { font-size: 20px; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ (Ø§Ù„Ù…ÙˆØ¯Ù„ + Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…)
# ==========================================
@st.cache_resource
def load_resources():
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯Ù„
    if os.path.exists("discharge_prediction_model.pkl"):
        model = joblib.load("discharge_prediction_model.pkl")
    else:
        st.error("Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ¯Ù„ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯! ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ ÙƒÙˆØ¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø£ÙˆÙ„Ø§Ù‹.")
        return None, None, None, None, None

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…
    try:
        patients = pd.read_csv("Dataset/hosp/patients.csv")
        admissions = pd.read_csv("Dataset/hosp/admissions.csv")
        chartevents = pd.read_csv("Dataset/icu/chartevents.csv")
        labevents = pd.read_csv("Dataset/hosp/labevents.csv")

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ù…Ù‡Ù…Ø©
        chartevents["charttime"] = pd.to_datetime(chartevents["charttime"])
        labevents["charttime"] = pd.to_datetime(labevents["charttime"])
        admissions["admittime"] = pd.to_datetime(admissions["admittime"])

        return model, patients, admissions, chartevents, labevents
    except FileNotFoundError as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        return None, None, None, None, None

# ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ø´ÙŠØ¡ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
model_pipeline, patients_df, admissions_df, chartevents_df, labevents_df = load_resources()

# ==========================================
# 3. Ø¯ÙˆØ§Ù„ ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ÙŠØ¶ (Feature Extraction)
# ==========================================
def get_patient_live_data(subject_id, hadm_id):
    """ØªØ³ØªØ®Ø±Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ù„Ù…Ø±ÙŠØ¶ ÙˆØªØ¹Ø§Ù„Ø¬Ù‡Ø§ Ø¨Ù†ÙØ³ Ø·Ø±ÙŠÙ‚Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯Ù„"""

    # 1. Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠØ©
    pat_info = patients_df[patients_df["subject_id"] == subject_id].iloc[0]
    adm_info = admissions_df[admissions_df["hadm_id"] == hadm_id].iloc[0]

    # ØªØ­Ø¯ÙŠØ¯ ÙˆÙ‚Øª Ø§Ù„Ù€ Snapshot (Ø¨Ø¹Ø¯ 24 Ø³Ø§Ø¹Ø©)
    t0 = adm_info["admittime"] + pd.Timedelta(hours=24)

    # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø­ÙŠÙˆÙŠØ© (Vitals)
    VITAL_ITEMS = {
        "heart_rate": [220045], "sbp": [220179],
        "resp_rate": [220210], "spo2": [220277]
    }

    vitals_data = {}
    for name, ids in VITAL_ITEMS.items():
        subset = chartevents_df[
            (chartevents_df["hadm_id"] == hadm_id) &
            (chartevents_df["itemid"].isin(ids)) &
            (chartevents_df["charttime"] <= t0)
        ]

        if not subset.empty:
            vitals_data[f"{name}_mean"] = subset["valuenum"].mean()
            vitals_data[f"{name}_min"] = subset["valuenum"].min()
            vitals_data[f"{name}_max"] = subset["valuenum"].max()
        else:
            vitals_data[f"{name}_mean"] = np.nan
            vitals_data[f"{name}_min"] = np.nan
            vitals_data[f"{name}_max"] = np.nan

    # 3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªØ­Ø§Ù„ÙŠÙ„ (Labs)
    LAB_ITEMS = {
        "creatinine": [50912], "wbc": [51300],
        "hemoglobin": [51222], "sodium": [50983]
    }

    labs_data = {}
    for name, ids in LAB_ITEMS.items():
        subset = labevents_df[
            (labevents_df["hadm_id"] == hadm_id) &
            (labevents_df["itemid"].isin(ids)) &
            (labevents_df["charttime"] <= t0)
        ]

        if not subset.empty:
            last_val = subset.sort_values("charttime").iloc[-1]["valuenum"]
            labs_data[f"{name}_last"] = last_val
        else:
            labs_data[f"{name}_last"] = np.nan

    # 4. ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ØµÙ (Row) Ù„Ù„Ù…ÙˆØ¯Ù„
    row = {
        "anchor_age": pat_info["anchor_age"],
        "gender": 1 if pat_info["gender"] == "M" else 0,
    }
    row.update(vitals_data)
    row.update(labs_data)

    return row, adm_info["admission_type"], pat_info["gender"]

def predict_with_model(row_data, admission_type):
    input_df = pd.DataFrame([row_data])

    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù€ Missing Indicators
    cols_to_check = [c for c in input_df.columns if "mean" in c or "last" in c or "max" in c or "min" in c]
    for col in cols_to_check:
        input_df[f"{col}_missing"] = input_df[col].isnull().astype(int)

    # Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù€ admission_type Ø§Ù„Ø£ØµÙ„ÙŠ
    input_df["admission_type"] = admission_type

    # Ø³ÙˆÙŠ get_dummies
    input_df = pd.get_dummies(input_df, columns=["admission_type"], prefix="admission_type")

    # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ø¹ Ø§Ù„Ù…ÙˆØ¯Ù„
    if hasattr(model_pipeline.named_steps['scaler'], 'feature_names_in_'):
        required_cols = model_pipeline.named_steps['scaler'].feature_names_in_
        input_df = input_df.reindex(columns=required_cols, fill_value=0)

    # ØªØ¹Ø¨Ø¦Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
    input_df = input_df.fillna(input_df.median())
    input_df = input_df.fillna(0)

    # Ø§Ù„ØªÙˆÙ‚Ø¹
    prob = model_pipeline.predict_proba(input_df)[0][1]

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù‡Ù… Ø§Ù„Ø¹ÙˆØ§Ù…Ù„
    coefs = model_pipeline.named_steps['model'].coef_[0]
    if len(coefs) == len(input_df.columns):
        contributions = input_df.values[0] * coefs
        contrib_df = pd.DataFrame({
            'Feature': input_df.columns,
            'Contribution': contributions
        }).sort_values(by='Contribution', key=abs, ascending=False).head(5)
    else:
        contrib_df = pd.DataFrame()

    return prob, contrib_df, input_df

# ==========================================
# 4. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Sidebar)
# ==========================================
st.sidebar.title("Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
st.sidebar.header("Ø¨Ø­Ø« Ø¹Ù† Ù…Ø±ÙŠØ¶")

if admissions_df is not None:
    available_subjects = admissions_df['subject_id'].unique()
    patient_id = st.sidebar.selectbox("Ø§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ù…Ù„Ù (Subject ID)", available_subjects)

    hadm_ids = admissions_df[admissions_df['subject_id'] == patient_id]['hadm_id'].unique()
    hadm_id = st.sidebar.selectbox("Ø§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ø¯Ø®ÙˆÙ„ (HADM ID)", hadm_ids)

    run_analysis = st.sidebar.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© ğŸ”")
else:
    st.error("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…Ø­Ù…Ù„Ø©.")
    run_analysis = False

# ==========================================
# 5. Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (Main Dashboard)
# ==========================================
if run_analysis and model_pipeline is not None:
    with st.spinner('Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯Ù„...'):

        row_data, adm_type, gender_str = get_patient_live_data(patient_id, hadm_id)
        prob, contrib_df, input_df_scaled = predict_with_model(row_data, adm_type)

        col1, col2 = st.columns([1, 3])
        with col2:
            st.title(f"Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙŠØ¶: {patient_id}")
            st.caption(f"Ø±Ù‚Ù… Ø§Ù„Ø¯Ø®ÙˆÙ„: {hadm_id} | ÙˆÙ‚Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„: {pd.Timestamp.now().strftime('%H:%M')}")
            st.markdown(f"**Ø§Ù„Ø¹Ù…Ø±:** {row_data['anchor_age']} | **Ø§Ù„Ø¬Ù†Ø³:** {gender_str} | **Ù†ÙˆØ¹ Ø§Ù„Ø¯Ø®ÙˆÙ„:** {adm_type}")

        st.divider()

        # Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        c1, c2 = st.columns([2, 1])

        with c1:
            st.subheader("ğŸ“Š Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Real-Time)")
            prob_percent = int(prob * 100)

            if prob > 0.6:
                color = "#28a745"
                status = "Ù…Ø±Ø´Ø­ Ù„Ù„Ø®Ø±ÙˆØ¬ (Discharge)"
                box_color = "#d4edda"
            elif prob > 0.3:
                color = "#ffc107"
                status = "ØªØ­Øª Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø© (Observation)"
                box_color = "#fff3cd"
            else:
                color = "#dc3545"
                status = "ÙŠØªØ·Ù„Ø¨ Ø¨Ù‚Ø§Ø¡ (Stay)"
                box_color = "#f8d7da"

            st.markdown(f"""
            <div style="background-color: {box_color}; padding: 20px; border-radius: 15px; border-left: 10px solid {color}; text-align: center;">
                <h1 style="color: {color}; font-size: 50px; margin:0;">{prob_percent}%</h1>
                <h3 style="margin:0; color: #333;">Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø®Ø±ÙˆØ¬ Ø®Ù„Ø§Ù„ 48 Ø³Ø§Ø¹Ø©</h3>
                <p style="font-size: 18px; font-weight: bold; margin-top: 10px;">Ø§Ù„ØªÙˆØµÙŠØ©: {status}</p>
            </div>
            """, unsafe_allow_html=True)

        with c2:
            st.info("â„¹ï¸ Ù‡Ø°Ù‡ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª MIMIC-IV Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø§Ù„Ù…Ø­Ù…Ù„Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù….")

        st.divider()

        # Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
        st.subheader("ğŸ“ˆ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¯Ø®Ù„Ø© Ù„Ù„Ù…ÙˆØ¯Ù„")
        m1, m2, m3, m4 = st.columns(4)

        def fmt(val): return f"{val:.1f}" if pd.notnull(val) else "N/A"

        m1.metric("Avg HR", fmt(row_data.get('heart_rate_mean')))
        m2.metric("Avg SpO2", fmt(row_data.get('spo2_mean')))
        m3.metric("Last WBC", fmt(row_data.get('wbc_last')))
        m4.metric("Last Creatinine", fmt(row_data.get('creatinine_last')))

        # Ø§Ù„ØªÙØ³ÙŠØ± - Coefficients
        if not contrib_df.empty:
            st.subheader("ğŸ”§ Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ø¹ÙˆØ§Ù…Ù„ (Feature Coefficients)")
            st.bar_chart(contrib_df.set_index('Feature')['Contribution'])
            st.caption("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙˆØ¬Ø¨Ø© ØªØ¯ÙØ¹ Ù†Ø­Ùˆ Ø§Ù„Ø®Ø±ÙˆØ¬ØŒ Ø§Ù„Ø³Ø§Ù„Ø¨Ø© ØªØ¯ÙØ¹ Ù†Ø­Ùˆ Ø§Ù„Ø¨Ù‚Ø§Ø¡.")
        else:
            st.warning("Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ù† Ø­Ø³Ø§Ø¨ ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø¨Ø¯Ù‚Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ø±ÙŠØ¶.")

        # SHAP Explanation
        st.divider()
        st.subheader("ğŸ§  Ø´Ø±Ø­ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SHAP")
        
        try:
            # ØªØ­Ù…ÙŠÙ„ SHAP data Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªÙˆÙØ±Ø©
            if os.path.exists("shap_values_data.pkl"):
                shap_data = joblib.load("shap_values_data.pkl")
                
                # Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
                shap_values_test = shap_data['shap_values']
                X_test_scaled = pd.DataFrame(
                    shap_data['X_test_scaled'],
                    columns=shap_data['X_test_scaled_columns']
                )
                background_sample = pd.DataFrame(
                    shap_data['background_sample'],
                    columns=shap_data['background_columns']
                )
                expected_value = shap_data['expected_value']
                
                # Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ SHAP explainer Ù„Ù„Ù…Ø±ÙŠØ¶ Ø§Ù„Ø­Ø§Ù„ÙŠ ÙÙ‚Ø·
                scaler = model_pipeline.named_steps['scaler']
                input_scaled = scaler.transform(input_df_scaled.values)
                input_scaled_df = pd.DataFrame(input_scaled, columns=input_df_scaled.columns)
                
                # Ø§Ø³ØªØ®Ø¯Ù… KernelExplainer Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ SHAP values Ù„Ù„Ù…Ø±ÙŠØ¶ Ø§Ù„Ø­Ø§Ù„ÙŠ
                current_explainer = shap.KernelExplainer(
                    model_pipeline.named_steps['model'].predict,
                    background_sample
                )
                shap_value_patient = current_explainer.shap_values(input_scaled_df)
                
                st.info("ğŸ’¡ **SHAP ÙŠØ´Ø±Ø­ ÙƒÙŠÙ ÙŠØªÙ†Ø¨Ø£ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:**")
                st.write("""
                - ÙƒÙ„ Ù…ÙŠØ²Ø© Ù„Ù‡Ø§ ØªØ£Ø«ÙŠØ± Ù…Ø¹ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø¨Ø¤
                - Ø§Ù„Ø£Ø­Ù…Ø±: ÙŠØ²ÙŠØ¯ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø®Ø±ÙˆØ¬
                - Ø§Ù„Ø£Ø²Ø±Ù‚: ÙŠÙ‚Ù„Ù„ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø®Ø±ÙˆØ¬
                - Ø§Ù„Ø­Ø¬Ù…: Ù‚ÙˆØ© Ø§Ù„ØªØ£Ø«ÙŠØ±
                """)
                
                # Ø¹Ø±Ø¶ Ø£Ù‡Ù… Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø§Øª
                st.write("**Ø£Ù‡Ù… 5 Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¤Ø«Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø¨Ø¤:**")
                shap_summary = pd.DataFrame({
                    'Feature': input_df_scaled.columns,
                    'SHAP Value': np.abs(shap_value_patient[0])
                }).nlargest(5, 'SHAP Value')
                
                st.dataframe(shap_summary, use_container_width=True)
                
                # Force plot (Text version)
                st.write("**ØªÙØµÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤:**")
                
                positive_effects = []
                negative_effects = []
                
                for feat, shap_val in zip(input_df_scaled.columns, shap_value_patient[0]):
                    if shap_val > 0:
                        positive_effects.append((feat, shap_val))
                    else:
                        negative_effects.append((feat, abs(shap_val)))
                
                positive_effects.sort(key=lambda x: x[1], reverse=True)
                negative_effects.sort(key=lambda x: x[1], reverse=True)
                
                force_text = f"""
**Ø§Ù„ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© (ØªØ²ÙŠØ¯ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø®Ø±ÙˆØ¬):**
"""
                for feat, shap_val in positive_effects[:5]:
                    force_text += f"\n- {feat}: +{shap_val:.4f}"
                
                force_text += f"\n\n**Ø§Ù„ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ø³Ù„Ø¨ÙŠØ© (ØªÙ‚Ù„Ù„ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø®Ø±ÙˆØ¬):**"
                for feat, shap_val in negative_effects[:5]:
                    force_text += f"\n- {feat}: -{shap_val:.4f}"
                
                st.info(force_text)
                
            else:
                st.warning("âš ï¸ Ø¨ÙŠØ§Ù†Ø§Øª SHAP ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©. ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")
        except Exception as e:
            st.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ SHAP: {str(e)}")
            st.info("Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ³ÙŠØ±Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Coefficients Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ.")

elif not run_analysis:
    st.info("ğŸ‘ˆ Ø§Ø®ØªØ± Ù…Ø±ÙŠØ¶Ø§Ù‹ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„Ø¨Ø¯Ø¡.")
